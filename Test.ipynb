{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "# Import Numpy \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import Seaborn and Matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Re\n",
    "\n",
    "import re\n",
    "\n",
    "# Import Math\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### iloc Properties\n",
    "\n",
    "Single Column:            df.iloc[:,3]\n",
    "\n",
    "List of Columns:          df.iloc[:,[3,5,6]]\n",
    "\n",
    "Slice of Columns:         df.iloc[:,3:7]\n",
    "    \n",
    "Single Row:               df.iloc[20]\n",
    "    \n",
    "List of Rows:             df.iloc[[0,3,8]]\n",
    "    \n",
    "Slice of Rows:            df.iloc[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Along Row/Column Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating result along row/column axis\n",
    "\n",
    "## Calculate along row axis\n",
    "## Caculate result for each column\n",
    "Axis = 0\n",
    "Axis = \"index\"\n",
    "\n",
    "## Calculate along column axis\n",
    "## Calculate result for each row\n",
    "Axis = 1\n",
    "Axis = \"column\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Boolean Indexing\n",
    "\n",
    "bool_value = df[\"column_1\"] == 0\n",
    "df.loc[bool_value,\"column_1\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Title Related Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Strip Whitespace in Columns\n",
    "\n",
    "new_columns = []\n",
    "\n",
    "for i in df.columns:\n",
    "    new_columns.append(i.strip())\n",
    "    \n",
    "df.columns = new_columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Column Editing\n",
    "\n",
    "def new_func(word):\n",
    "    word = word.strip()\n",
    "    word = word.replace(\" \",\"_\")\n",
    "    word = word.replace('(', '')\n",
    "    word = word.replace(')', '')\n",
    "    word = word.lower()\n",
    "    return word\n",
    "\n",
    "new_columns = []\n",
    "for c in df.columns:\n",
    "    clean_c = new_func(c)\n",
    "    new_columns.append(clean_c)\n",
    "    \n",
    "df.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming Columns\n",
    "\n",
    "df[\"column_1\"] = df[\"column_1\"].str.replace('GB','').astype(int)\n",
    "df.rename({\"column_1\":\"column_new_name\"},axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Fields Realted Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing non-digit characters from column fields\n",
    "\n",
    "df[\"column_1\"] = df[\"column_1\"].str.replace('GB','')\n",
    "new_series = df[\"column_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting strings to numeric dtypes \n",
    "\n",
    "df[\"column_1\"] = df[\"column_1\"].str.replace('GB','')\n",
    "df[\"column_1\"] = df[\"column_1\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting Values from Strings\n",
    "\n",
    "df[\"column_1\"] = (df[\"column_1\"].str.split().str[0])\n",
    "df[\"column_2\"] = (df[\"column_2\"].str.split().str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correcting Bad Values in Columns Fields\n",
    "\n",
    "mapping_dict = {\n",
    "    'Android': 'Android',\n",
    "    'Chrome OS': 'Chrome OS',\n",
    "    'Linux': 'Linux',\n",
    "    'Mac OS': 'macOS',\n",
    "    'No OS': 'No OS',\n",
    "    'Windows': 'Windows',\n",
    "    'macOS': 'macOS'\n",
    "}\n",
    "\n",
    "df[\"column_1\"] = df[\"column_1\"].map(mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop rows/columns with nulls\n",
    "\n",
    "df_no_null_rows = df.dropna()\n",
    "\n",
    "df_no_null_cols = df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filling missing values using Boolean Indexing where relation is between columns\n",
    "\n",
    "bool_array = df[\"column_1\"] == \"No OS\"\n",
    "df.loc[bool_array, \"os_version\"] = \"Version Unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace units and change to float type\n",
    "### Rename columns\n",
    "### Save to CSV\n",
    "\n",
    "df[\"weight\"] = df[\"weight\"].str.replace(\"kgs\",\"\").str.replace(\"kg\",\"\").astype(float)\n",
    "df.rename({\"weight\": \"weight_kg\"}, axis=1, inplace=True)\n",
    "df.to_csv('laptops_cleaned.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look for Duplicates\n",
    "\n",
    "df['Column_1'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for nulls\n",
    "\n",
    "df['column_1'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check how many nulls\n",
    "\n",
    "df['column_1'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check stats for this column\n",
    "\n",
    "df['column_1'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacement of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We replace the nulls with the median value\n",
    "\n",
    "df['column_1'].fillna(df['column_1'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace Nulls with logic\n",
    "\n",
    "df['column_1'].where(df['column_1'] > 1918, df['column_1'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datepart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SaleDate we split the column into various possible columns such as Year, Month, Day etc.\n",
    "# We use fast.ai add_datepart function to do the splitting\n",
    "\n",
    "def add_datepart(df, fldname, drop=True):\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "        \n",
    "add_datepart(df, 'saledate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check histogram to spot any anomalies in the data of a column\n",
    "\n",
    "plt.hist(df['Column_1'],color = 'blue', edgecolor = 'black',bins = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply Method\n",
    "\n",
    "def label(element):\n",
    "    if element > 1:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Low'\n",
    "    \n",
    "economy_apply = df['Column_1'].apply(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series.str.split()    Splits each element in the Series.\n",
    "Series.str.strip()    Strips whitespace from each string in the Series.\n",
    "Series.str.lower()    Converts strings in the Series to lowercase.\n",
    "Series.str.upper()    Converts strings in the Series to uppercase.\n",
    "Series.str.get()      Retrieves the ith element of each element in the Series.\n",
    "Series.str.replace()  Replaces a regex or string in the Series with another string.\n",
    "Series.str.cat()      Concatenates strings in a Series.\n",
    "Series.str.extract()  Extracts substrings from the Series matching a regex pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "df = pd.read_csv(\"file.csv\", low_memory = False, parse_dates = True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(file_name, encoding='utf-8', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
